# -*- coding: utf-8 -*-
"""Construction_Site_Captioning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kbaNH2qx7C_Szdj_70Z9Y8riPrJBWXjZ
"""

# !pip install streamlit

# ==============================
# STREAMLIT CIVIL CAPTION APP
# ==============================
import streamlit as st
from transformers import BlipForConditionalGeneration, AutoTokenizer
from PIL import Image
import torch

# Load model from Hugging Face Hub
model_name = "kneelabh87/blip-finetuned-construction_updated"
model = BlipForConditionalGeneration.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)

st.title("BLIP Fine-tuned Image Captioning")

uploaded_file = st.file_uploader("Upload an image", type=["jpg", "jpeg", "png"])

if uploaded_file:
    image = Image.open(uploaded_file).convert("RGB")
    st.image(image, caption="Uploaded Image", use_container_width=True)

    inputs = tokenizer(images=image, return_tensors="pt")
    with torch.no_grad():
        output = model.generate(**inputs, max_new_tokens=30)

    caption = tokenizer.decode(output[0], skip_special_tokens=True)
    st.subheader("Generated Caption")
    st.write(caption)





